# Ch 12: Unsupervised

```elixir
Mix.install([
  {:scidata, "~> 0.1"},
  {:axon, "~> 0.5"},
  {:exla, "~> 0.5"},
  {:nx, "~> 0.5"},
  {:kino, "~> 0.8"}
])
```

## Root

```elixir
Nx.global_default_backend(EXLA.Backend)
```

## Autoencoder

```elixir
batch_size = 64
{{data, type, shape}, _} = Scidata.MNIST.download()

train_data =
  data
  |> Nx.from_binary(type)
  # imgs are 28px by 28px and grayscale (1 colour channel)
  |> Nx.reshape({:auto, 28, 28, 1})
  |> Nx.divide(255)
  |> Nx.to_batched(batch_size)
```

```elixir
defmodule Autoencoder do
  def encoder(input) do
    input
    |> Axon.flatten()
    |> Axon.dense(256, activation: :relu, name: "encoder_dense_0")
    |> Axon.dense(128, activation: :relu, name: "encoder_dense_1")
  end

  def decoder(input) do
    input
    |> Axon.dense(256, activation: :relu, name: "decoder_dense_0")
    |> Axon.dense(784, activation: :sigmoid, name: "decoder_dense_1")
    |> Axon.reshape({:batch, 28, 28, 1})
  end
end
```

```elixir
model =   
  Axon.input("image")   
  |> Autoencoder.encoder()   
  |> Autoencoder.decoder()     

```

```elixir
test_batch = Enum.at(train_data, 0)

test_image =
  test_batch[0]
  |> Nx.new_axis(0)

visualize_test_image = fn %Axon.Loop.State{step_state: step_state} = state ->
  out_image =
    Axon.predict(
      model,
      step_state[:model_state],
      test_image,
      compiler: EXLA
    )

  out_image =
    out_image
    |> Nx.multiply(255)
    # Kino.Image expects image tensors to be created from u8 tensors
    |> Nx.as_type(:u8)
    |> Nx.reshape({28, 28, 1})

  Kino.Image.new(out_image)
  |> Kino.render()

  {:continue, state}
end
```

```elixir
trained_model_state =
  model
  |> Axon.Loop.trainer(:mean_squared_error, Polaris.Optimizers.adam(learning_rate: 1.0e-3))
  |> Axon.Loop.handle_event(:epoch_completed, visualize_test_image)
  |> Axon.Loop.run(
    Stream.zip(train_data, train_data),
    %{},
    epochs: 5,
    compiler: EXLA
  )
```

By treating the input as both the input and label, you’ve turned this unsupervised learning problem into a supervised learning problem.

It’s difficult to interpret how this loss corresponds to how well your model is reconstructing compressed inputs. A much more interpretable measure of progress is a periodic visualization of your model’s outputs on some example data, which comes from the anon function bound to visualise_test_image.

<!-- livebook:{"break_markdown":true} -->

In this example, your decoder is actually kind of a generative model—it takes a latent representation and produces an output. Hypothetically, you can skip the encoder altogether and give the decoder some random latent representation, and it should give you an output that resembles a handwritten digit:

```elixir
decoder_only =
  Axon.input("noise")
  |> Autoencoder.decoder()

key = Nx.Random.key(42)
{noise, _key} = Nx.Random.normal(key, shape: {1, 128})
out_image = Axon.predict(decoder_only, trained_model_state, noise)
upsampled = Axon.Layers.resize(out_image, size: {512, 512})

out_image =
  upsampled
  |> Nx.reshape({512, 512, 1})
  |> Nx.multiply(255)
  |> Nx.as_type(:u8)

Kino.Image.new(out_image)
```

> Unfortunately, you didn’t force your model to have a latent space with structure. The structure of your encoded representations is at the mercy of a neural network and gradient descent. You can’t pass random uniform or normal noise to your decoder and expect coherent output because your decoder only knows how to handle latent representations produced by the encoder. But what if there was a way to force your encoder to learn a structured representation, which you can easily query later on? Fortunately, there is. Enter the variational autoencoder.

## Variational autoencoder
